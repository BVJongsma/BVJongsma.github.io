---
layout: dinky
---
<!-- experiment -->
<div id="experiment">
    <h1>Experiment</h1>
    <p>
        As explained in the Model section, an implementation of Clue in Python was created.
        This program makes use of a Kripke model and public and private announcements are used to update this
        model, so agents can eventually determine the cards in the envelope.
        We will now consider various strategies that can be used to determine the cards in the envelope and discuss
        their performance.
    </p>
    <div id="strategies">
    <h2>The strategies</h2>
    <p>
        Below we will outline the strategies that the players can use to select cards they will ask the next player
        about. These strategies vary in how much information is used. In some cases, no such cards exist and then
        the model will default to selecting one or both cards at random.
    </p>
    <ul>
        <li>RANDOM: randomly pick a weapon and suspect card.</li>
        <li>NOT_OWN: pick a weapon card and a suspect card that the agent does not have themselves.</li>
        <li>ONE_OWN: pick a weapon and a suspect card, one of which the agent has themselves and another that the
            agent does not have themselves. </li>
        <li>UNKNOWN: pick a weapon and a suspect card for which the agent does not know to whom they belong.</li>
        <li>ONE_UNKNOWN: pick a weapon and a suspect card, where the agent knows who has one card, but not the other.</li>
        <li>REASONING: pick a weapon and a suspect card. Pick one card that the agent knows about and isn't of the next
            agent, so you do not see the same card multiple times. Pick the other card, so that it might be of the next
            agent or in the envelope. For this card you do not know where it is yet, and you know it might still belong
            to the next agent, so this should give you a lot of information. If there are no such cards: select one that
            might be of the next agent.</li>
    </ul>
    </div>

    <div id="experimental-setup">
    <h2>The experimental setup</h2>
        <p>
            We tested the strategies mentioned above versus the random strategy. Player 1 would get one of the strategies
            and the other players would use the random strategy. For each strategy, we ran the model until a winner was
            found ten times and determined the average amount of steps and the win rate of the first
            player. The division of cards among the players and the envelope was randomised, and players responded
            with cards they had already shown if they had both cards.
        </p>
    </div>
</div>

<!-- results -->
<div id="results">
    <h1>Results</h1>
    <p>
        Table 1 shows the results for all the strategies after 10 runs. There is a large difference between strategies
        for the win rate of player 1. There are 3 players, so you would expect player 1 to win about 33% of the time.
        The strategies ONE_OWN and REASONING perform worse with respectively a 20 and 30% win rate for player 1.
        The ONE_UNKNOWN strategy gives the best performance with a win rate of 70% for player 1.
        The difference in the amount of turns
        per player is on average quite small, with a minimum of 5.6 turns when player 1 only asks for cards not owned
        and a maximum of 6.9 turns per player when player 1 asks for one unknown card. This makes sense, as asking for
        the cards that update the most knowledge should generally lead to faster games.
    </p>

<table>
  <caption>Table 1. Results after 10 runs for all strategies.</caption>
  <tr>
    <th></th>
    <th>NOT_OWN</th>
    <th>ONE_OWN</th>
    <th>UNKNOWN</th>
    <th>ONE_UNKNOWN</th>
    <th>REASONING</th>
  </tr>
  <tr>
    <th>Win rate player 1</th>
    <td>60%</td>
    <td>20%</td>
    <td>50%</td>
    <td>70%</td>
    <td>30%</td>
  </tr>
  <tr>
    <th>Average amount of turns per player</th>
    <td>5.6</td>
    <td>6.5</td>
    <td>6</td>
    <td>6.9</td>
    <td>5.8</td>
  </tr>
</table>

    <p>
        When solely considering win rate, the ONE_UNKNOWN strategy gives the best performance. However, the NOT_OWN
        strategy only has 1 win less and has less average turns per player. The difference in performance could
        potentially be explained away because of random initialisation / the other players selecting random cards.
        Having many cards from one category and not from another can heavily influence the amount of initial relations
        for a player. Moreover, if two players ask for a card that is in the envelope and do not get shown any cards,
        then it is easy to determine that this card is in the envelope, resulting in much faster convergence to the
        solution than in some other cases.
    </p>

    <p>
        This performance measure indicates that ONE_UNKNOWN and NOT_OWN give the best performance. However, we did
        not take into account performance against other strategies, as some of these strategies might work really
        well if another player uses another strategy than randomly selecting cards. Moreover, we worked with a
        simplified version of the game and some of these strategies might start to show better performance when using
        more cards. So, it would be interesting to consider a direct comparison of strategies in future research instead
        of comparing against a random strategy, as well as using less simplifications in the model.
    </p>
</div>


<!-- TODO discussion -->
<div id="discussion">
    <h1>Discussion</h1>
</div>

